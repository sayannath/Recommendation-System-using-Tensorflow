# -*- coding: utf-8 -*-
"""Recommendation System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10rbeU6XY4083Tu2PLi6aNy2CMTIGjMe_
"""

import tensorflow as tf
print(tf.__version__)

from sklearn.utils import shuffle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import keras
print(keras.__version__)
from keras.layers import Input, Dense, Embedding, Flatten, Concatenate
from keras.models import Model
from keras.optimizers import SGD, Adam

!wget -nc http://files.grouplens.org/datasets/movielens/ml-20m.zip

# Unzip
!unzip -n ml-20m.zip

df = pd.read_csv('ml-20m/ratings.csv')
df.head()

df.userId = pd.Categorical(df.userId)
df['new_user_id'] = df.userId.cat.codes

df.movieId = pd.Categorical(df.movieId)
df['new_movie_id'] = df.movieId.cat.codes

user_ids = df['new_user_id'].values
movie_ids = df['new_movie_id'].values
ratings = df['rating'].values

N = len(set(user_ids))
M = len(set(movie_ids))

print(N)
print(M)

#Set embedding Dimension
K = 10

# Neural Network

# user input
u = Input(shape=(1,))

#movie input
m = Input(shape=(1,))

#User Embedding
u_emb = Embedding(N, K)(u)  #output is (num_samples, 1, K)

#Movie Embedding
m_emb = Embedding(M, K)(m) #output is (num_samples, 1, K)

#Flatten both the embeddings
u_emb = Flatten()(u_emb)
m_emb = Flatten()(m_emb)

#Concatenate user-move into a new feature vector
x = Concatenate()([u_emb, m_emb]) #now it's a (num_samples, 2K)

#Now that we have a feature vector, it's just a regular ANN
x = Dense(1024, activation='relu')(x)
x = Dense(400, activation='relu')(x)
x = Dense(400, activation='relu')(x)
x = Dense(1)(x)

#Build the model and compile
model  = Model(inputs=[u, m], outputs=x)
model.compile(loss='mse', optimizer=SGD(learning_rate=0.08, momentum=0.9),)

#split the data
user_ids, movie_ids, ratings = shuffle(user_ids, movie_ids, ratings)
Ntrain = int(0.8 * len(ratings))

train_user = user_ids[:Ntrain]
train_movie = movie_ids[:Ntrain]
train_ratings = ratings[:Ntrain]

test_user = user_ids[Ntrain:]
test_movie = movie_ids[Ntrain:]
test_ratings = ratings[Ntrain:]

#center the ratings
avg_rating = train_ratings.mean()
train_ratings = train_ratings - avg_rating
test_ratings = test_ratings - avg_rating

model.summary()

r = model.fit(
    x=[train_user, train_movie],
    y=train_ratings,
    epochs=25,
    batch_size=1024,
    verbose=2,
    validation_data=([test_user, test_movie], test_ratings),
)

#plot losses
plt.plot(r.history['loss'], label="train_loss")
plt.plot(r.history['val_loss'], label="val_loss")
plt.legend()
plt.show()

np.sqrt(0.6259)

model.save('systemRecommend.h5')

